{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb492ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e121d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emc_pre_engine import EmC_Pre_Generator\n",
    "from emc_net_engine import EmC_Net_Generator\n",
    "from emc_order_engine import EmC_Order_Box\n",
    "from emc_loss import masked_mse\n",
    "from logger_engine import EmC_Logger\n",
    "from emc_aux_fun import netsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34484e0a",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Random Targets\n",
    "\n",
    "dim_imp,dim_ptrn = 24,37\n",
    "sample_sizes = [4000,4000,4000,4000,4000]\n",
    "minmaxes = [(0,0.0082),(0,0.0058),(0,0.0047),(0,0.0041),(0,0.0036)] # PEC Reflection \n",
    "\n",
    "seq_len = 20\n",
    "dim_order = 2\n",
    "\n",
    "emc_order_box = EmC_Order_Box(\"scaler/scale_0_0d01.save\",norm_idx = True,env_dim = 2)\n",
    "emc_order_box.generate_rnd(dim_ptrn,sample_sizes,minmaxes,seq_len,\n",
    "                           inc_split = 13,\n",
    "                           frq_split = 21,frq_range = (10,20))\n",
    "\n",
    "t_size = 0.2\n",
    "o_train,o_test,e_train,e_test,t_train,t_test,c_train,c_test = emc_order_box.split_orders(t_size,return_beam_number = True )\n",
    "print(o_train,o_test,e_train,e_test,t_train,t_test,c_train,c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ecbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emc_order_box.env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8a5d2",
   "metadata": {},
   "source": [
    "## Build and Load emc_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2202514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "batch_size = 100\n",
    "emc_net_generator = EmC_Net_Generator(dim_order,dim_imp,dim_ptrn,env_dim = 2, target_seq_len = seq_len,batch_size = batch_size)\n",
    "emc_net_generator.set_pre_conv(layer_num = 2,cluster = [3,2], channel = 1024, \n",
    "                               env_on_all_conv = False)\n",
    "emc_net_generator.set_pre_fc(layer_num = 3,size = 1600)\n",
    "emc_net_generator.set_inv_rnn(layer_num = 2, size = [512,1024],rnd_init = True)\n",
    "emc_net_generator.set_inv_fc(layer_num = 3, size = 1024, actvfun = \"relu\",limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eaca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_pre = \"emc_pre_curve_incfqr\"\n",
    "uid_pre = \"ek2ao3\" # ID of the predictor just trained\n",
    "para_pre = \"epoch045-loss0.000401.hdf5\" # Parameter to use\n",
    "\n",
    "logger_pre = EmC_Logger(folder_pre,uid = uid_pre)\n",
    "logger_pre.print_msg()\n",
    "\n",
    "(_,dir_pre) = logger_pre.get_ids()\n",
    "para_pre_name = f\"{dir_pre}/network_para/{para_pre}\"\n",
    "print(f\"Pre network to be loaded: {para_pre_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "(emc_inv,emc_net) = emc_net_generator.create_EmC_Net()\n",
    "emc_net_generator.load_pre_net(emc_net,para_pre_name)\n",
    "\n",
    "emc_net.summary()\n",
    "emc_inv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f901b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"emc_net_curve_incfrq\"\n",
    "\n",
    "logger = EmC_Logger(foldername)\n",
    "(uid,dirname) = logger.get_ids()\n",
    "\n",
    "logger.write_msg(f\"Network hyperparameter summary: \\n{emc_net_generator}\")\n",
    "logger.write_msg(f\"Network structure: \\n{netsummary(emc_net)}\")\n",
    "data_msg = \"Training on random dataset: \\n\"\n",
    "data_msg += f\"{dim_order} x {seq_len}\\n\"\n",
    "data_msg += f\"{sample_sizes}\\n\"\n",
    "data_msg += f\"{minmaxes}\\n\"\n",
    "data_msg += f\"test sizes: {t_size}\"\n",
    "logger.write_msg(data_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 120\n",
    "learning_rate = 5e-5\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=dirname+\"/network_para/epoch{epoch:03d}-loss{val_loss:.6f}.hdf5\",\n",
    "    monitor=\"val_loss\",verbose=1, save_best_only=True,save_weights_only=True, mode=\"min\")\n",
    "emc_net.compile(loss=masked_mse, optimizer=opt)\n",
    "\n",
    "logger.write_msg(f\"# of epoch = {n_epochs} \\n Batch size = {batch_size} \\n Optimazation with Adam, learning rate {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b754d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.write_msg(f\"Training starts\")\n",
    "history = emc_net.fit([o_train,e_train], t_train, validation_data=([o_test,e_test], t_test), \n",
    "                      epochs=n_epochs, batch_size=batch_size, shuffle=True,\n",
    "                      callbacks=[checkpoint])\n",
    "logger.write_msg(f\"Training finished\")\n",
    "np.savetxt(f\"{dirname}/loss.txt\",history.history['loss'])\n",
    "np.savetxt(f\"{dirname}/val_loss.txt\",history.history['val_loss'])\n",
    "logger.write_msg(f\"Losses saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967ca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch=list(range(1,n_epochs+1))\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "#Plot loss vs epoch\n",
    "plt.rc('font', size=14) \n",
    "plt.plot(num_epoch, history.history['loss'])\n",
    "plt.plot(num_epoch, history.history['val_loss'])\n",
    "plt.legend(('Training Set','Validation Set'), fontsize=12, loc=1)\n",
    "plt.xlabel('Epoch #', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.xlim(1,n_epochs)\n",
    "plt.ylim(0,0.05)\n",
    "plt.xticks(list(range(0,n_epochs,100)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55404a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_scaler = joblib.load(\"scaler/scale_4d3_4d7.save\")\n",
    "inc_scaler = joblib.load(\"scaler/scale_m30_30.save\")\n",
    "ptrn_scaler = joblib.load(\"scaler/scale_0_0d01.save\")\n",
    "vol_scaler = joblib.load(\"scaler/scale_0_18.save\")\n",
    "\n",
    "t_predict = emc_net.predict([o_test,e_test],batch_size = batch_size)\n",
    "\n",
    "theta = np.arange(0, np.pi+np.pi/36, np.pi/36)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "for n_example in range (0,25):\n",
    "    y_example = ptrn_scaler.inverse_transform(t_test[n_example,:].reshape(1, -1))\n",
    "    y_predictn = ptrn_scaler.inverse_transform(t_predict[n_example,:].reshape(1, -1))\n",
    "    a_example = inc_scaler.inverse_transform(e_test[n_example,:].reshape(1,-1))[0,0]\n",
    "    f_example = freq_scaler.inverse_transform(e_test[n_example,:].reshape(1,-1))[0,1]\n",
    "    \n",
    "    #plt.subplot(5,5,n_example+1,projection = 'polar')\n",
    "    plt.subplot(5,5,n_example+1)\n",
    "    plt.rc('font', size=8)\n",
    "    plt.plot(theta, y_predictn.reshape(dim_ptrn,1))\n",
    "    plt.plot(theta, y_example.reshape(dim_ptrn,1),'o')\n",
    "    plt.ylim(0,0.008)\n",
    "    plt.rc('font', size=8)\n",
    "    plt.text(1,0.006,f\"{a_example:.0f} deg\", fontsize=12)\n",
    "    plt.text(1,0.005,f\"{f_example:.2f} GHz\", fontsize=12)\n",
    "    if n_example == 0: plt.legend(('Prediction','Target'), fontsize=12, loc=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
